{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Data Mining Exercise 5  - kNN, SVM\n",
    "exercise-number: 5\n",
    "other-links:\n",
    "  - text: Aufgabenblatt 5 \n",
    "    href: \"../../../../_aufgaben/Aufgabenblaetter/5/05_Customer_data_kNN_SVM_student.pdf\"\n",
    "    icon: file-pdf\n",
    "code-links:\n",
    "  - text: Aufgabenblatt 5 \n",
    "    href: \"../../../../_aufgaben/Aufgabenblaetter/5/05_Customer_data_kNN_SVM_student.ipynb\"\n",
    "    type: \"application/octet-stream\"\n",
    "    icon: file-code\n",
    "downloads: [ipynb]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 - kNN & SVM\n",
    "Necessary libraries are being loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Extract from the data preparation\n",
    "Explain with comments in the code what is performed here by the individual commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>daytime</th>\n",
       "      <th>isHoliday</th>\n",
       "      <th>distance</th>\n",
       "      <th>count</th>\n",
       "      <th>startClusterName</th>\n",
       "      <th>startClusterZip</th>\n",
       "      <th>startClusterID</th>\n",
       "      <th>endClusterName</th>\n",
       "      <th>endClusterZip</th>\n",
       "      <th>endClusterID</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Di</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>Hunedoara</td>\n",
       "      <td>71171</td>\n",
       "      <td>3254026000002</td>\n",
       "      <td>Hunedoara</td>\n",
       "      <td>71171</td>\n",
       "      <td>3254026000007</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Turda</td>\n",
       "      <td>80982</td>\n",
       "      <td>3241013050002</td>\n",
       "      <td>Turda</td>\n",
       "      <td>80982</td>\n",
       "      <td>3241013050008</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sa</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Turda</td>\n",
       "      <td>80982</td>\n",
       "      <td>3241013050007</td>\n",
       "      <td>Turda</td>\n",
       "      <td>80982</td>\n",
       "      <td>3241013030001</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fr</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>Bran</td>\n",
       "      <td>91157</td>\n",
       "      <td>3254028001012</td>\n",
       "      <td>Bran</td>\n",
       "      <td>91157</td>\n",
       "      <td>3254028001004</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fr</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>Bran</td>\n",
       "      <td>91157</td>\n",
       "      <td>3254028001003</td>\n",
       "      <td>Turda</td>\n",
       "      <td>80982</td>\n",
       "      <td>3241013070001</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  weekday  daytime  isHoliday  distance  count startClusterName  \\\n",
       "0      Di        7          0         3     15        Hunedoara   \n",
       "1      Mi       17          0         0     10            Turda   \n",
       "2      Sa       11          0         3     10            Turda   \n",
       "3      Fr       13          0         0     15             Bran   \n",
       "4      Fr       18          0         7     10             Bran   \n",
       "\n",
       "   startClusterZip  startClusterID endClusterName  endClusterZip  \\\n",
       "0            71171   3254026000002      Hunedoara          71171   \n",
       "1            80982   3241013050002          Turda          80982   \n",
       "2            80982   3241013050007          Turda          80982   \n",
       "3            91157   3254028001012           Bran          91157   \n",
       "4            91157   3254028001003          Turda          80982   \n",
       "\n",
       "    endClusterID  year  month  total  \n",
       "0  3254026000007  2021      3     45  \n",
       "1  3241013050008  2021      3      0  \n",
       "2  3241013030001  2021      3     30  \n",
       "3  3254028001004  2021      3      0  \n",
       "4  3241013070001  2021      3     70  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv('prepared_data.csv')\n",
    "\n",
    "dfPrepared = df.copy()\n",
    "dfPrepared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 One-Hot-Encoding & Normalization\n",
    "Now carry out binary encoding for all relevant features and save the result in the dfTrans data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daytime</th>\n",
       "      <th>isHoliday</th>\n",
       "      <th>distance</th>\n",
       "      <th>count</th>\n",
       "      <th>startClusterZip</th>\n",
       "      <th>startClusterID</th>\n",
       "      <th>endClusterZip</th>\n",
       "      <th>endClusterID</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Sa</th>\n",
       "      <th>Sam</th>\n",
       "      <th>So/Fe</th>\n",
       "      <th>start_Bran</th>\n",
       "      <th>start_Hunedoara</th>\n",
       "      <th>start_Turda</th>\n",
       "      <th>end_Bran</th>\n",
       "      <th>end_Hunedoara</th>\n",
       "      <th>end_Turda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>71171</td>\n",
       "      <td>3254026000002</td>\n",
       "      <td>71171</td>\n",
       "      <td>3254026000007</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>80982</td>\n",
       "      <td>3241013050002</td>\n",
       "      <td>80982</td>\n",
       "      <td>3241013050008</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>80982</td>\n",
       "      <td>3241013050007</td>\n",
       "      <td>80982</td>\n",
       "      <td>3241013030001</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>91157</td>\n",
       "      <td>3254028001012</td>\n",
       "      <td>91157</td>\n",
       "      <td>3254028001004</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>91157</td>\n",
       "      <td>3254028001003</td>\n",
       "      <td>80982</td>\n",
       "      <td>3241013070001</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   daytime  isHoliday  distance  count  startClusterZip  startClusterID  \\\n",
       "0        7          0         3     15            71171   3254026000002   \n",
       "1       17          0         0     10            80982   3241013050002   \n",
       "2       11          0         3     10            80982   3241013050007   \n",
       "3       13          0         0     15            91157   3254028001012   \n",
       "4       18          0         7     10            91157   3254028001003   \n",
       "\n",
       "   endClusterZip   endClusterID  year  month  ...    Mon     Sa    Sam  So/Fe  \\\n",
       "0          71171  3254026000007  2021      3  ...  False  False  False  False   \n",
       "1          80982  3241013050008  2021      3  ...  False  False  False  False   \n",
       "2          80982  3241013030001  2021      3  ...  False   True  False  False   \n",
       "3          91157  3254028001004  2021      3  ...  False  False  False  False   \n",
       "4          80982  3241013070001  2021      3  ...  False  False  False  False   \n",
       "\n",
       "   start_Bran  start_Hunedoara  start_Turda  end_Bran  end_Hunedoara  \\\n",
       "0       False             True        False     False           True   \n",
       "1       False            False         True     False          False   \n",
       "2       False            False         True     False          False   \n",
       "3        True            False        False      True          False   \n",
       "4        True            False        False     False          False   \n",
       "\n",
       "   end_Turda  \n",
       "0      False  \n",
       "1       True  \n",
       "2       True  \n",
       "3      False  \n",
       "4       True  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# space\n",
    "dfPrepared = pd.get_dummies(dfPrepared, prefix='',prefix_sep='',columns=['weekday'])\n",
    "dfPrepared = pd.get_dummies(dfPrepared, prefix='start',prefix_sep='_',columns=['startClusterName'])\n",
    "dfPrepared = pd.get_dummies(dfPrepared, prefix='end',prefix_sep='_',columns=['endClusterName'])\n",
    "\n",
    "dfPrepared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the correlations with the heat map. Remove characteristics that correlate 100% with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(dfTrans.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all non-binary attributes must be normalized. This time minmax_scale should be used for this. Use comments to explain the function of the individual lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "dfnorm = dfTrans.copy()\n",
    "\n",
    "scaled = minmax_scale(dfnorm[['age_first_order','pages_visited_avg']], feature_range = (0, 1))\n",
    "\n",
    "dfnorm['age_first_order'] = scaled[:,0] \n",
    "dfnorm['pages_visited_avg'] = scaled[:,1]\n",
    "\n",
    "dfnorm[['age_first_order', 'pages_visited_avg']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have a short look at our prepared dataframe. all numeric columns with a natural order are standardised and scaled. all columns without a natural order are one-hot encoded. Our target column ‘high revenue’ is also binary. we want it that way because we perform a classification and either assign a data record to high revenue (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Training & evaluation of the models\n",
    "\n",
    "In the following, the algorithms kNN and SVM are to be trained and tested. For this purpose, a data split of 70 % (training data) to 30 % (test data) must be carried out in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = dfnorm.drop(['high revenue'], axis = 1)\n",
    "y = dfnorm['high revenue'].astype(int)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                    random_state = 101, stratify = y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1: k-Nearest Neighbors (kNN)\n",
    "Train the kNN on the training data and evaluate on the test data. Test different values for k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following visualisation will help you to try out good ks. Here you can see again the change in the error rate with different k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "error_rate = []\n",
    "\n",
    "k_range = range(1, 30)\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = knn.predict(x_test)\n",
    "    \n",
    "    error_rate.append(1 - accuracy_score(y_test, y_pred))  \n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(k_range, error_rate, color='blue', linestyle='dashed', marker='o', \n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Elbow method for KNN')\n",
    "plt.xlabel('Number of neighbours: k')\n",
    "plt.ylabel('Error rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the distribution of the predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Count how many data points were classified as 0 and how many as 1\n",
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "\n",
    "# Calculate percentage distribution\n",
    "total = len(y_pred)\n",
    "percentages = (counts / total) * 100\n",
    "\n",
    "# Output of the results\n",
    "for u, count, percentage in zip(unique, counts, percentages):\n",
    "    print(f'Class {u}: {count} Datapoints ({percentage:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution also becomes apparent when we visualise the data points. Note: The n-dimensional space is reduced to 3 dimensions using PCA (theoretical Background not part of the class!) in order to make visualisation possible . PCA (Principal Component Analysis) does not simply select three existing features, but creates new features (the so-called principal components), which are linearly combined variables of the original features. The aim is to reduce the dimensions in such a way that the maximum possible variance is retained in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Dimension reduction to 3 dimensions using PCA\n",
    "pca = PCA(n_components=3)\n",
    "x_train_pca = pca.fit_transform(x_train)\n",
    "x_test_pca = pca.transform(x_test)\n",
    "\n",
    "# Visualisation of the test data points\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create a scatter plot with the test data and the prediction (y_pred) as colours\n",
    "scatter = ax.scatter(x_test_pca[:, 0], x_test_pca[:, 1], x_test_pca[:, 2], \n",
    "                     c=y_pred, cmap='viridis', s=50, alpha=0.8)\n",
    "\n",
    "# Add colour bars to display the classes\n",
    "legend1 = ax.legend(*scatter.legend_elements(), title=\"classes\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "# Axis labelling\n",
    "ax.set_xlabel('PCA 1')\n",
    "ax.set_ylabel('PCA 2')\n",
    "ax.set_zlabel('PCA 3')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation\n",
    "Then use the scorer or other addressed methods to evaluate the Confusion Matrix and the accuracy of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "print(f'True Positive Rate (TPR): {tpr:.2f}')\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "print(f'False Positive Rate (FPR): {fpr:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "y_proba = knn_model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1.1 kNN with shepards method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For comparison, look at the same algorithm but with Shepard's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=23, weights='distance')\n",
    "knn_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = knn_model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2: Support Vector Machine\n",
    "Train an SVM on the training data and evaluate on the test data. Test with the parameter transfer (kernel = 'rbf', gamma = 'scale')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation\n",
    "Then use the scorer or other addressed methods to evaluate the Confusion Matrix and the accuracy of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Count how many data points were classified as 0 and how many as 1\n",
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "\n",
    "# Calculate percentage distribution\n",
    "total = len(y_pred)\n",
    "percentages = (counts / total) * 100\n",
    "\n",
    "# Output of the results\n",
    "for u, count, percentage in zip(unique, counts, percentages):\n",
    "    print(f'Class {u}: {count} Datapoints ({percentage:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "print(f'True Positive Rate (TPR): {tpr:.2f}')\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "print(f'False Positive Rate (FPR): {fpr:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Activate SVC model with probabilities\n",
    "svm_model = SVC(kernel='rbf', gamma='scale', random_state=1, probability=True)\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict probabilities (only for the positive class)\n",
    "y_prob = svm_model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "# Plot the ROC-Curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for SVM Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the algorithms\n",
    "Assess the quality of the two algorithms by evaluating the results. Which one would you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Optimization with GridSearch ( Preview)\n",
    "Gridsearch is a method for hyperparameter optimization. Gridsearch iteratively tries out all combinations of the selected parameters. The combination with the highest score is then output.\n",
    "\n",
    "For the sake of simplicity, cross-validation is not used in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(random_state = 1)\n",
    "param_grid1 = {\"kernel\": [\"poly\", \"rbf\", \"sigmoid\"], \n",
    "              \"gamma\": [\"scale\",\"auto\"] }\n",
    "gridSearch1 = GridSearchCV(estimator = svm_model, param_grid = param_grid1)\n",
    "gridSearch1.fit(x_train, y_train)\n",
    "\n",
    "results1 = pd.DataFrame(gridSearch1.cv_results_)\n",
    "\n",
    "params1 = results1.loc[results1['rank_test_score'].idxmax()]\n",
    "params1['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to train the model with the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the ConfusionMatrix again and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "print(f'True Positive Rate (TPR): {tpr:.2f}')\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "print(f'False Positive Rate (FPR): {fpr:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='sigmoid', gamma='scale', random_state=1, probability=True)\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "y_prob = svm_model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for SVM Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1: k-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now convert GridSearch for k-Nearest Neighbors and select different values for metric and n_neighbors in param_grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the ConfusionMatrix again and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "print(f'True Positive Rate (TPR): {tpr:.2f}')\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "print(f'False Positive Rate (FPR): {fpr:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "y_proba = knn_model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "although our true positive rate has improved, the ROC-curve has deteriorated. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
